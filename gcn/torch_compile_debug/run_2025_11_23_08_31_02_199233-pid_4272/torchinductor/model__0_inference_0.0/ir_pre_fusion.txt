buf0: SchedulerNode(ComputedBuffer)
buf0.writes = [MemoryDep('buf0', c0, {c0: 10556}, None)]
buf0.unmet_dependencies = []
buf0.met_dependencies = 
    [   MemoryDep('arg0_1', c0 + 10556, {c0: 10556}, None),
        MemoryDep('arg0_1', c0, {c0: 10556}, None)]
buf0.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf0.group.device = cuda:0
buf0.group.iteration = (10556, 1)
buf0.sizes = ([10556], [])
arg0_1_layout = FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1])
arg0_1_layout = FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1])
buf0_layout = FixedLayout('cuda', torch.bool, size=[10556], stride=[1])
class buf0_loop_body:
    var_ranges = {z0: 10556}
    index0 = z0
    index1 = z0 + 10556
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg0_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg0_1', get_index_1)
        ne = ops.ne(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf0', get_index_2, ne, None)
        return store
buf0 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[16384], 
        filename=__file__,
        triton_meta={'signature': {0: '*i64', 1: '*i1', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A1A999C712D012AAAD112A22ED69BAC53DFBBA6EAF7D0DB3123EC6062FEB150E', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 10556
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (10556 + x0), xmask)
        tmp2 = tmp0 != tmp1
        tl.store(out_ptr0 + (x0), tmp2, xmask)


buf1: SchedulerNode(ComputedBuffer)
buf1.writes = [MemoryDep('buf1', c0, {c0: 5416}, None)]
buf1.unmet_dependencies = []
buf1.met_dependencies = []
buf1.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
buf1.group.device = cuda:0
buf1.group.iteration = (5416, 1)
buf1.sizes = ([2, 2708], [])
buf1_layout = FixedLayout('cuda', torch.int64, size=[2, 2708], stride=[2708, 1])
class buf1_loop_body:
    var_ranges = {z0: 2, z1: 2708}
    index0 = z1
    index1 = 2708*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf1', get_index_1, index_expr, None)
        return store
buf1 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[8192], 
        filename=__file__,
        triton_meta={'signature': {0: '*i64', 1: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0,), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A1A999C712D012AAAD112A22ED69BAC53DFBBA6EAF7D0DB3123EC6062FEB150E', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 5416
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex % 2708
        x2 = xindex
        tmp0 = x0
        tl.store(out_ptr0 + (x2), tmp0, xmask)


